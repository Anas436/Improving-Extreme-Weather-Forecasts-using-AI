{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kflW8ta2a4W"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgdga68p2a4c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IONb6hXa2a4e"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_ZE3mez2a4f"
   },
   "outputs": [],
   "source": [
    "# variable plotting\n",
    "\n",
    "def attribute_plot(data, time, attribute, plot_name):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(data[time], data[attribute])\n",
    "    #labels = data[time]\n",
    "    #plt.legend()\n",
    "    plt.xlabel(xlabel=time)\n",
    "    plt.ylabel(ylabel=attribute)\n",
    "    #plt.xticks(data[time], labels, rotation='vertical')\n",
    "    plt.title(label=plot_name)\n",
    "    plt.grid(True)\n",
    "    \n",
    "# distribution plotting\n",
    "\n",
    "def distribution(data, attribute, title):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(data[attribute], alpha=0.5)\n",
    "    plt.axvline(data[attribute].median(), color='r', linestyle='dashed', linewidth=2, label='median value')\n",
    "    plt.axvline(data[attribute].mean(), color='purple', linestyle='dashed', linewidth=2, label='average value')\n",
    "    plt.axvline(data[attribute].quantile(0.25), color='r', linestyle='dotted', linewidth=3, label='25% and 75% values')\n",
    "    plt.axvline(data[attribute].quantile(0.75), color='r', linestyle='dotted', linewidth=3)\n",
    "    plt.legend()\n",
    "    plt.title(label=title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKtxoc2K2a4g"
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQah1inh2a4g",
    "outputId": "0e6b06d4-2f1d-4c6f-f170-52a4047388f0"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzrYr9XC2a4i",
    "outputId": "2d67acbb-19b1-4471-a4fc-3946918a21b6"
   },
   "outputs": [],
   "source": [
    "# what features we have?\n",
    "\n",
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONODsBVr2a4j"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7eauF5t2a4j"
   },
   "source": [
    "### Data types verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJh_N79B2a4k",
    "outputId": "d92e7ac8-93f8-4f60-ff3f-cfbb36556ca3"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sk2yfDxb2a4l",
    "outputId": "cf9e113f-7f45-4bbe-e5b0-b207402a7f4e"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrSNPSoz2a4l",
    "outputId": "01387cb5-f616-4654-f1de-da3402cc4a69"
   },
   "outputs": [],
   "source": [
    "# change date format from 'object' to 'datetime'\n",
    "\n",
    "data['startdate'] = pd.to_datetime(data['startdate'])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qRxhXRg2a4m",
    "outputId": "8a87157c-f7df-4dae-f95c-003bd7fb517c"
   },
   "outputs": [],
   "source": [
    "# what feature has type 'object' besides the date?\n",
    "\n",
    "data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bwylwKA2a4n"
   },
   "source": [
    "### Missing values and duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BzY60hj2a4n",
    "outputId": "47822237-49b6-4f74-db3b-32d0ca349197"
   },
   "outputs": [],
   "source": [
    "data.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p15mzr3i2a4o",
    "outputId": "f0c62826-26dd-489d-bc6a-e2bb25959c46"
   },
   "outputs": [],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATGTh9nn2a4o",
    "outputId": "3ac61ed5-b0d6-4075-c05d-7c5e7c5351ae"
   },
   "outputs": [],
   "source": [
    "missing_values = data.isna().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djnQG-2n2a4p"
   },
   "source": [
    "There are 8 variables with missing values. All of them related to weather models forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdOcToV_2a4p",
    "outputId": "54539e33-bbda-4570-f634-f5b253da0d83"
   },
   "outputs": [],
   "source": [
    "msno.matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1rVrRUMX2a4q",
    "outputId": "f65fdb9b-d4bc-4c76-f5d3-9e2916306b98"
   },
   "outputs": [],
   "source": [
    "msno.bar(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vl8vJ01p2a4q"
   },
   "source": [
    "### Features description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whadU8N22a4q"
   },
   "source": [
    "Date: startdate\n",
    "\n",
    "Static features\n",
    "Geoposition: lat, lon, elevation__elevation, climateregions__climateregion\n",
    "\n",
    "Dynamics features\n",
    "\n",
    "1. Environmental features (humidity, pressure, water): contest-pevpr-sfc-gauss-14d__pevpr – evaporation, contest-rhum-sig995-14d__rhum – relative humidity, contest-slp-14d__slp – sea level pressure, contest-pres-sfc-gauss-14d__pres – pressure, contest-prwtr-eatm-14d__prwtr – precipitable water for entire atmosphere, contest-precip-14d__precip – measured precipitation\n",
    "\n",
    "2. Wind:\n",
    "- Longitudinal wind: contest-wind-vwnd-925-14d__wind-vwnd-925, contest-wind-vwnd-250-14d__wind-vwnd-250\n",
    "- Zonal wind: contest-wind-uwnd-250-14d__wind-uwnd-250, contest-wind-uwnd-925-14d__wind-uwnd-925\n",
    "- Geopotential height wind: contest-wind-h10-14d__wind-hgt-10 – height 10,contest-wind-h100-14d__wind-hgt-100  – height 100, contest-wind-h500-14d__wind-hgt-500 – height 500, contest-wind-h850-14d__wind-hgt-850 – height 850\n",
    "\n",
    "3. Temperature - target: the arithmetic mean of the max and min observed temperature over the next 14 days for each location and start date: contest-tmp2m-14d__tmp2m \n",
    "\n",
    "4. Temperature computed by weather models:\n",
    "- recent forecasts from different weather models: cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- sea surface temperature: sst-2010-1 - sst-2010-10\n",
    "- most recent monthly NMME model forecasts for target and average forecast across those models (nmme0mean): nmme0-tmp2m-34w__cancm30, nmme0-tmp2m-34w__cancm40, nmme0-tmp2m-34w__ccsm30, nmme0-tmp2m-34w__ccsm40, nmme0-tmp2m-34w__cfsv20, nmme0-tmp2m-34w__gfdlflora0, nmme0-tmp2m-34w__gfdlflorb0, nmme0-tmp2m-34w__gfdl0, nmme0-tmp2m-34w__nasa0, nmme0-tmp2m-34w__nmme0mean\n",
    "- weeks 3-4 weighted average of most recent monthly NMME model forecasts for target label: nmme-tmp2m-34w__cancm3, nmme-tmp2m-34w__cancm4, nmme-tmp2m-34w__ccsm3, nmme-tmp2m-34w__ccsm4, nmme-tmp2m-34w__cfsv2, nmme-tmp2m-34w__gfdl, nmme-tmp2m-34w__gfdlflora, nmme-tmp2m-34w__gfdlflorb, nmme-tmp2m-34w__nasa, nmme-tmp2m-34w__nmmemean\n",
    "- weeks 5-6 weighted average of most recent monthly NMME model forecasts for target label: nmme-tmp2m-56w__cancm3, nmme-tmp2m-56w__cancm4, nmme-tmp2m-56w__ccsm3, nmme-tmp2m-56w__ccsm4, nmme-tmp2m-56w__cfsv2, nmme-tmp2m-56w__gfdl, nmme-tmp2m-56w__gfdlflora, nmme-tmp2m-56w__gfdlflorb, nmme-tmp2m-56w__nasa, nmme-tmp2m-56w__nmmemean\n",
    "\n",
    "5. Precipitation computed by weather models:\n",
    "- weeks 3-4 weighted average of monthly NMME model forecasts for precipitation: nmme-prate-34w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 5-6 weighted average of monthly NMME model forecasts for precipitation: nmme-prate-56w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 3-4 weighted average of most recent monthly NMME model forecasts for precipitation: nmme0-prate-34w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 5-6 weighted average of most recent monthly NMME model forecasts for precipitation: nmme0-prate-56w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "\n",
    "Features related to El Nino:\n",
    "1. Sea ice concentration: icec-2010-1 - icec-2010-10, where 1-10 - years after the El Nino\n",
    "2. Oscillation coefficients:\n",
    "- Madden-Julian oscillation: mjo1d__phase, mjo1d__amplitude\n",
    "- Multivariate ENSO index (MEI) (associated with El Nino/Southern Oscillation (ENSO)): mei__mei, mei__meirank, mei__nip\n",
    "3. Wind\n",
    "- Longitudinal wind: wind-vwnd-250-2010-1 - wind-vwnd-250-2010-20, wind-vwnd-925-2010-1 - wind-vwnd-925-2010-20\n",
    "- Zonal wind: wind-uwnd-250-2010-1 - wind-uwnd-250-2010-10\n",
    "- Geopotential height wind: wind-hgt-10-2010-1 - wind-hgt-10-2010-10, wind-hgt-100-2010-1 - wind-hgt-100-2010-10, wind-hgt-500-2010-1 - wind-hgt-500-2010-10, wind-hgt-850-2010-1 - wind-hgt-850-2010-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5ENbfsR2a4r"
   },
   "source": [
    "### Target investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nu0hqPlF2a4s",
    "outputId": "142393a2-44b3-42c4-ca11-438e494d4b14"
   },
   "outputs": [],
   "source": [
    "# five point summary\n",
    "\n",
    "data['contest-tmp2m-14d__tmp2m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6nFWFJX2a4s",
    "outputId": "2c945d0e-672d-46d3-ef82-855f1bdca369"
   },
   "outputs": [],
   "source": [
    "attribute_plot(data, 'startdate', 'contest-tmp2m-14d__tmp2m', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M04w52U62a4t",
    "outputId": "720e919b-4bb8-4f99-86ea-44957ea3d523"
   },
   "outputs": [],
   "source": [
    "distribution(data, 'contest-tmp2m-14d__tmp2m', 'Target distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay6t2hX62a4t"
   },
   "source": [
    "The target (temperature) has a distribution similar to the normal. However, the average value is not equal to the median value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo7-p5hc2a4t"
   },
   "source": [
    "### Locations investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkjY60wO2a4u",
    "outputId": "a0dbee71-dba4-417f-c758-c20167eaf874"
   },
   "outputs": [],
   "source": [
    "# How many locations we have?\n",
    "\n",
    "data.groupby(['lat', 'lon'], as_index=False, sort=False).aggregate('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyH6yv-H2a4u"
   },
   "source": [
    "We have 514 locations and 731 measurements for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiSN9aqG2a4v",
    "outputId": "012b5c8b-b513-4a84-9397-1334739f053c"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['lon'], data['lat'])\n",
    "plt.xlabel(xlabel='latitude')\n",
    "plt.ylabel(ylabel='longitude')\n",
    "plt.title(label='Locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD9YhHNy2a4v"
   },
   "source": [
    "### Climatic regions investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUvfRVE32a4v",
    "outputId": "20fd3431-24ba-4d3c-ffed-e959ab081eef"
   },
   "outputs": [],
   "source": [
    "# How many climatic regions we have?\n",
    "\n",
    "data.groupby('climateregions__climateregion', as_index=False).aggregate('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ktmwe3r2a4w"
   },
   "source": [
    "15 climatic regions and different measurements for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RShdfBOP2a4w",
    "outputId": "0969865b-26f9-4f2d-f7ca-7f57ef7b132e"
   },
   "outputs": [],
   "source": [
    "data['climateregions__climateregion'].value_counts().plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RPMrTHO2a4w"
   },
   "source": [
    "Description:\n",
    "1. B (Dry):\n",
    "- BWh = Hot desert climate\n",
    "- BWk = Cold desert climate\n",
    "- BSh = Hot semi-arid climate\n",
    "- BSk = Cold semi-arid climate\n",
    "2. C (Temperate Climates):\n",
    "- Cfa = Humid subtropical climate\n",
    "- Cfb = Temperate oceanic climate or subtropical highland climate\n",
    "- Csa = Hot-summer Mediterranean climate\n",
    "- Csb = Warm-summer Mediterranean climate\n",
    "3. D (Continental climates):\n",
    "- Dfa = Hot-summer humid continental climate\n",
    "- Dfb = Warm-summer humid continental climate\n",
    "- Dwa = Monsoon-influenced hot-summer humid continental climate\n",
    "- Dwb = Monsoon-influenced warm-summer humid continental climate\n",
    "- Dsb = Mediterranean-influenced warm-summer humid continental climate\n",
    "- Dsc = Mediterranean-influenced subarctic climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GO7Xw22R2a4x",
    "outputId": "8fe99779-4348-4835-a740-ac5db5de159d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(data=data, x='lon', y='lat', hue = 'climateregions__climateregion', palette = 'Spectral')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(xlabel='latitude')\n",
    "plt.ylabel(ylabel='longitude')\n",
    "plt.title(label='Locations of the climatic regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM2NuNZB2a4x",
    "outputId": "7c953ad3-f2ae-44ed-be80-24f77922b595"
   },
   "outputs": [],
   "source": [
    "# How many locations in each climatic region?\n",
    "\n",
    "data['locations'] = data['lat'].astype(str) + '; ' + data['lon'].astype(str)\n",
    "locations = data[['lat', 'lon', 'climateregions__climateregion', 'locations']].drop_duplicates()\n",
    "locations.groupby('climateregions__climateregion', as_index=False, sort=False).aggregate({'locations' : 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFxMJyuj2a4y",
    "outputId": "e8b978b5-2a6d-4dcc-a04d-1008e8c296b4"
   },
   "outputs": [],
   "source": [
    "# transform climatic regions from categorical to numeric format to work further\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "data['climateregions__climateregion'] = labelencoder.fit_transform(data['climateregions__climateregion'].values)\n",
    "\n",
    "# We can visualize numeric climatic regions to be sure that we have got all 14 regions\n",
    "\n",
    "data['climateregions__climateregion'].value_counts().plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfO2GX8n2a4y",
    "outputId": "fc3c0c49-713e-4217-c98a-b065fc5adcd8"
   },
   "outputs": [],
   "source": [
    "# we can also transform locations from (lat; lon) to just numeric format like the climatic regions to simplify the work\n",
    "\n",
    "data['locations'] = labelencoder.fit_transform(data['locations'].values)\n",
    "data['locations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D31W1nqg2a4z"
   },
   "source": [
    "### Features investigation and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3v0r6Cnm2a4z"
   },
   "source": [
    "For the modeling step, the environmental features were selected by the team through the provided EDA. That is why only these features takes into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylH0SBmy2a4z",
    "outputId": "7b526453-0fb0-48d8-a337-e753a23be924"
   },
   "outputs": [],
   "source": [
    "environmental_features = data[['startdate', 'lat', 'lon', 'elevation__elevation', 'climateregions__climateregion', 'locations',\\\n",
    "                           'contest-pevpr-sfc-gauss-14d__pevpr', 'contest-rhum-sig995-14d__rhum', \\\n",
    "                           'contest-slp-14d__slp', 'contest-pres-sfc-gauss-14d__pres', 'contest-prwtr-eatm-14d__prwtr',\\\n",
    "                           'contest-precip-14d__precip', 'contest-wind-h10-14d__wind-hgt-10',\\\n",
    "                     'contest-wind-h100-14d__wind-hgt-100', 'contest-wind-h500-14d__wind-hgt-500', \\\n",
    "                     'contest-wind-h850-14d__wind-hgt-850', 'contest-wind-vwnd-250-14d__wind-vwnd-250',\\\n",
    "                     'contest-wind-vwnd-925-14d__wind-vwnd-925','contest-wind-uwnd-250-14d__wind-uwnd-250',\\\n",
    "                     'contest-wind-uwnd-925-14d__wind-uwnd-925', 'contest-tmp2m-14d__tmp2m']]\n",
    "\n",
    "# rename some features for the clear description\n",
    "\n",
    "environmental_features = environmental_features.rename(columns={'elevation__elevation': 'elevation', \\\n",
    "                                                                'climateregions__climateregion': 'climateregion',\\\n",
    "                                                               'contest-pevpr-sfc-gauss-14d__pevpr': 'evaporation',\\\n",
    "                                                               'contest-rhum-sig995-14d__rhum': 'humidity',\\\n",
    "                                                               'contest-slp-14d__slp': 'sea_level_pressure',\\\n",
    "                                                               'contest-pres-sfc-gauss-14d__pres': 'pressure',\\\n",
    "                                                               'contest-prwtr-eatm-14d__prwtr': 'precipitable_water',\n",
    "                                                               'contest-precip-14d__precip': 'precipitation',\\\n",
    "                                                               'contest-wind-h10-14d__wind-hgt-10': 'wind_height_10',\\\n",
    "                                                               'contest-wind-h100-14d__wind-hgt-100': 'wind_height_100',\\\n",
    "                                                               'contest-wind-h500-14d__wind-hgt-500': 'wind_height_500',\\\n",
    "                                                               'contest-wind-h850-14d__wind-hgt-850': 'wind_height_850',\\\n",
    "                                                               'contest-wind-vwnd-250-14d__wind-vwnd-250': \\\n",
    "                                                                'long_wind_250', 'contest-wind-vwnd-925-14d__wind-vwnd-925':\\\n",
    "                                                               'long_wind_925', 'contest-wind-uwnd-250-14d__wind-uwnd-250':\\\n",
    "                                                               'zonal_wind_250', 'contest-wind-uwnd-925-14d__wind-uwnd-925':\\\n",
    "                                                               'zonal_wind_925', 'contest-tmp2m-14d__tmp2m': 'temperature'})\n",
    "\n",
    "# five point summary\n",
    "\n",
    "environmental_features.drop(columns={'startdate', 'lat', 'lon', 'climateregion', 'locations'}).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFTlqycO2a40",
    "outputId": "796fdb63-d20d-4181-a263-f62f9e99dfb1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "corr_matrix = environmental_features.drop(columns={'startdate', 'lat', 'lon', 'climateregion', 'locations'}).corr()\n",
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6PtAfOa2a40"
   },
   "source": [
    "The heatmap shows that\n",
    "1. we have high correlation between some features (|correlation|> 0.75):\n",
    "- elevation and pressure = -0.92\n",
    "- evaporation and humidity = -0.76\n",
    "- evaporation and wind height 10 = 0.75\n",
    "- wind height 10 and wind height 100 = 0.83\n",
    "- evaporation and wind height 100 = 0.82\n",
    "- evaporation and wind height 500 = 0.79\n",
    "- wind height 100 and wind height 500 = 0.96\n",
    "2. we have high correlation between temperature and \n",
    "- evaporation = 0.81\n",
    "- precipitable water = 0.77\n",
    "- wind height 10 = 0.76\n",
    "- wind height 100 = 0.9\n",
    "- wind height 500 = 0.88\n",
    "3. we have low correlation (|correlation|< 0.5) between temperature and\n",
    "- precipitation = 0.079\n",
    "- elevation = -0.21\n",
    "- pressure = 0.24\n",
    "- longitudinal wind 250 = 0.43\n",
    "- longitudinal wind 925 = 0.27\n",
    "- zonal wind 250 = -0.33\n",
    "- zonal wind 925 = -0.37\n",
    "\n",
    "The variables must be independent between each other. Therefore the high correlated features should be excluded at the modeling stage. The low correlated features should be also excluded as the less informative.\n",
    "We can remove wind height 10 and wind height 500. Although evaporation and temperature are high correlated we can also try to remove evaporation because of its high correlation with humidity and wind height 100, and observe what we will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPxyK5No2a41"
   },
   "outputs": [],
   "source": [
    "environmental_features_selected = environmental_features.drop(columns={'evaporation', 'wind_height_10', 'wind_height_500',\\\n",
    "                                                                       'elevation', 'precipitation', 'pressure',\\\n",
    "                                                                       'long_wind_250', 'long_wind_925', 'zonal_wind_250',\n",
    "                                                                       'zonal_wind_925'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEt8XfrA2a41",
    "outputId": "f936b45a-804b-4e4d-e19d-d25d81b1e55a"
   },
   "outputs": [],
   "source": [
    "corr_matrix_selected = environmental_features_selected.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".corr()\n",
    "sns.heatmap(corr_matrix_selected, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrSffhHA2a42"
   },
   "source": [
    "We have got 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV4whg5x2a42",
    "outputId": "cc22d97c-3d77-4cf1-f378-277dbd2f8133"
   },
   "outputs": [],
   "source": [
    "# features simple visualization\n",
    "\n",
    "environmental_features_selected.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".plot(figsize = (22, 16), subplots=True, layout=(len(environmental_features_selected.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A95S9hEu2a42"
   },
   "source": [
    "We have 514 locations and 14 climatic regions. The measurements are spread on the graphs through the whole time period.\n",
    "\n",
    "To try modeling step and interpret the results correctly, we can start simply from one location. Location # 1 for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpUq4WsZ2a43"
   },
   "source": [
    "### Location # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIos_mTU2a43",
    "outputId": "76c7b601-9e8a-4964-bffc-865aca920030"
   },
   "outputs": [],
   "source": [
    "location_1 = environmental_features_selected[environmental_features_selected['locations'] == 1]\n",
    "location_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frArMSJ92a43",
    "outputId": "a9160d61-8b32-49b3-e59a-7b22abaf6490"
   },
   "outputs": [],
   "source": [
    "# features simple visualization\n",
    "\n",
    "location_1.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".plot(figsize = (22, 16), subplots=True, layout=(len(location_1.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWyZm2Gt2a44"
   },
   "source": [
    "Now we can see variables dynamic for location # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAFsyFVL2a44"
   },
   "source": [
    "and their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJ9N-igc2a44",
    "outputId": "86517d2a-7397-4c59-81ed-5230ff4c7715"
   },
   "outputs": [],
   "source": [
    "location_1.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".hist(figsize = (8, 30), layout=(len(location_1.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZ21a5c32a45"
   },
   "source": [
    "### Features preparations to the modeling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpuNWB-z2a45",
    "outputId": "32a01303-00f2-4187-b186-94ced048a6a8"
   },
   "outputs": [],
   "source": [
    "# we take only date and necessary features for the prediction\n",
    "\n",
    "location_1 = location_1.drop(columns={'lat', 'lon', 'climateregion', 'locations'}).set_index('startdate')\n",
    "location_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6mTmICE2a46",
    "outputId": "5a50a56c-3a32-409d-bd40-89dc51b2d7bf"
   },
   "outputs": [],
   "source": [
    "location_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbBZiOoO2a46"
   },
   "outputs": [],
   "source": [
    "# normalizing the features\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset = scaler.fit_transform(location_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1cckQho2a46"
   },
   "source": [
    "This tutorial was used for the futher work:\n",
    "https://www.kaggle.com/code/mineshjethva/time-series-forecasting-with-lstm-for-uni-multivar/notebook\n",
    "\n",
    "We are going to use a multivariate approach since we have 5 features and the temperature itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vP26IAxh2a47"
   },
   "source": [
    "According to the task, we should predict the arithmetic mean of the maximum and minimum temperature over the next 14 days for each location and start date.\n",
    "To lean by steps, firstly we will try to predict just the values of the temperature for the next 14 days for one location by building LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKL1J5-k2a47"
   },
   "source": [
    "We want to predict the temperature 14 days in the future. We have 731 observations and one measurement per day. \n",
    "In order to make this prediction, we choose to use 90 days of observations. \n",
    "Thus, we would create a window containing the last 90 observations to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zI9DbxOS2a47"
   },
   "outputs": [],
   "source": [
    "# The function below returns the above described windows of time for the model to train on\n",
    "\n",
    "# history_size is the size of the past window of information\n",
    "# target_size is how far in the future does the model need to learn to predict, is the label that needs to be predicted\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "# \"multivariate\" means that we use several features (not one)\n",
    "    data = [] # for x_train/validation\n",
    "    labels = [] # for y_train/validation\n",
    "    start_index = start_index + history_size\n",
    "    \n",
    "    if end_index is None: # for the validation part\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index): # sequences creation \n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "        labels.append(target[i:i+target_size])\n",
    "        \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WYq-BM32a48"
   },
   "source": [
    "We do not use our test dataset and split the training dataset into training and validation parts to adjust the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rojijb1U2a48"
   },
   "outputs": [],
   "source": [
    "# setting the inputs for the function\n",
    "\n",
    "training_size = int(0.8*dataset.shape[0]) # define the size of training part\n",
    "start_index = 0\n",
    "end_index = training_size\n",
    "history_size = 90 # is the size of the past window of information\n",
    "target_size = 14 # days, is how far in the future does the model need to learn to predict, \n",
    "#is the label that needs to be predicted\n",
    "step = 1 # we have one measurement per day that is one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUDhnK822a49"
   },
   "outputs": [],
   "source": [
    "# # splitting the dataset into training and validation parts and transforming it with the described window\n",
    "\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, -1], start_index, end_index, history_size, target_size,\\\n",
    "                                                 step)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, -1], start_index, None, history_size, target_size, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "px-e3Gc62a49"
   },
   "source": [
    "Now we are ready to build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJx1l49B2a49"
   },
   "source": [
    "### Building LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-o4VUYu2a4-"
   },
   "outputs": [],
   "source": [
    "# We use tensorflow and keras to work with LSTM\n",
    "\n",
    "# perform shuffling, batching, and caching the dataset\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUI8ZdTM2a4-"
   },
   "outputs": [],
   "source": [
    "# constructing the model\n",
    "\n",
    "multi_step_model = tf.keras.models.Sequential()\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:]))\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "multi_step_model.add(tf.keras.layers.Dense(14))\n",
    "\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkigJPYc2a4-",
    "outputId": "ee0dad7f-4564-4cf2-a0ce-06e4be4387e7"
   },
   "outputs": [],
   "source": [
    "multi_step_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihNeoHbA2a4_",
    "outputId": "4e6468c2-c2f9-46f4-cbba-17bf979c054a"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(1):\n",
    "    print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnijJ3un2a4_",
    "outputId": "99d2bab1-7185-4469-a25e-b0d6f9a8fbba"
   },
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 20\n",
    "\n",
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1OzVTZ72a5A"
   },
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))\n",
    "\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, -1]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo', label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro', label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MT6mz69r2a5A",
    "outputId": "f4d565bb-d384-4cdf-f625-cd72e227cc56"
   },
   "outputs": [],
   "source": [
    "for x, y in train_data_multi.take(1):\n",
    "    multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0jYiE322a5A"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iQzNp3_2a5B",
    "outputId": "2f56b8ef-212f-4a66-c112-8802ab17dea5"
   },
   "outputs": [],
   "source": [
    "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L4nbpLH2a5B",
    "outputId": "1639fcf2-3a9b-4f0a-c4e8-89838846bc21"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "    multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1Q54AC22a5C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
