{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8Gxti1zTEC9"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNygEbeDTEDD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfdLwpxbTEDE"
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kY8EWen1TEDF"
   },
   "outputs": [],
   "source": [
    "# variable plotting\n",
    "\n",
    "def attribute_plot(data, time, attribute, plot_name):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(data[time], data[attribute])\n",
    "    #labels = data[time]\n",
    "    #plt.legend()\n",
    "    plt.xlabel(xlabel=time)\n",
    "    plt.ylabel(ylabel=attribute)\n",
    "    #plt.xticks(data[time], labels, rotation='vertical')\n",
    "    plt.title(label=plot_name)\n",
    "    plt.grid(True)\n",
    "    \n",
    "# distribution plotting\n",
    "\n",
    "def distribution(data, attribute, title):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(data[attribute], alpha=0.5)\n",
    "    plt.axvline(data[attribute].median(), color='r', linestyle='dashed', linewidth=2, label='median value')\n",
    "    plt.axvline(data[attribute].mean(), color='purple', linestyle='dashed', linewidth=2, label='average value')\n",
    "    plt.axvline(data[attribute].quantile(0.25), color='r', linestyle='dotted', linewidth=3, label='25% and 75% values')\n",
    "    plt.axvline(data[attribute].quantile(0.75), color='r', linestyle='dotted', linewidth=3)\n",
    "    plt.legend()\n",
    "    plt.title(label=title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cM4QEl84TEDG"
   },
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xIhLVKjTEDG",
    "outputId": "6309edcd-9c5b-4b81-a66d-af3ed1ae585b"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqUcHZUYTEDH",
    "outputId": "9a39ac05-d030-43e5-b50f-58e765430c53"
   },
   "outputs": [],
   "source": [
    "# what features we have?\n",
    "\n",
    "for i in data.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eY1ry-SvTEDI"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5kJ07e3TEDI"
   },
   "source": [
    "### Data types verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODSiRuQHTEDI",
    "outputId": "d260cae8-6165-4316-df50-4c3b688a3bc9"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETwf74zHTEDJ",
    "outputId": "c538688b-fd87-412e-e6dd-7b938947a9fb"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AY1GsDmMTEDJ",
    "outputId": "3dff650c-cdab-41e6-90d0-2d9d6a500160"
   },
   "outputs": [],
   "source": [
    "# change date format from 'object' to 'datetime'\n",
    "\n",
    "data['startdate'] = pd.to_datetime(data['startdate'])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh3g53RgTEDK",
    "outputId": "9978d2a1-7dbc-4bcc-f75e-2a6500f24000"
   },
   "outputs": [],
   "source": [
    "# what feature has type 'object' besides the date?\n",
    "\n",
    "data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4vRI-1zTEDK"
   },
   "source": [
    "### Missing values and duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evDLbCaOTEDK",
    "outputId": "eb5fe71c-7870-4c39-cfa8-143c99e285ed"
   },
   "outputs": [],
   "source": [
    "data.isna().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xuTzkuxTEDL",
    "outputId": "252b7bcf-9c9f-4856-ec4a-233eed591d64"
   },
   "outputs": [],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XwXg_oJTEDL",
    "outputId": "d100e24e-5271-46c4-f7da-35ff1ad400a8"
   },
   "outputs": [],
   "source": [
    "missing_values = data.isna().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cjx6QeyZTEDL"
   },
   "source": [
    "There are 8 variables with missing values. All of them related to weather models forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SEoXEILTEDM"
   },
   "source": [
    "### Features description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDAPgVKiTEDM"
   },
   "source": [
    "Date: startdate\n",
    "\n",
    "Static features\n",
    "Geoposition: lat, lon, elevation__elevation, climateregions__climateregion\n",
    "\n",
    "Dynamics features\n",
    "\n",
    "1. Environmental features (humidity, pressure, water): contest-pevpr-sfc-gauss-14d__pevpr – evaporation, contest-rhum-sig995-14d__rhum – relative humidity, contest-slp-14d__slp – sea level pressure, contest-pres-sfc-gauss-14d__pres – pressure, contest-prwtr-eatm-14d__prwtr – precipitable water for entire atmosphere, contest-precip-14d__precip – measured precipitation\n",
    "\n",
    "2. Wind:\n",
    "- Longitudinal wind: contest-wind-vwnd-925-14d__wind-vwnd-925, contest-wind-vwnd-250-14d__wind-vwnd-250\n",
    "- Zonal wind: contest-wind-uwnd-250-14d__wind-uwnd-250, contest-wind-uwnd-925-14d__wind-uwnd-925\n",
    "- Geopotential height wind: contest-wind-h10-14d__wind-hgt-10 – height 10,contest-wind-h100-14d__wind-hgt-100  – height 100, contest-wind-h500-14d__wind-hgt-500 – height 500, contest-wind-h850-14d__wind-hgt-850 – height 850\n",
    "\n",
    "3. Temperature - target: the arithmetic mean of the max and min observed temperature over the next 14 days for each location and start date: contest-tmp2m-14d__tmp2m \n",
    "\n",
    "4. Temperature computed by weather models:\n",
    "- recent forecasts from different weather models: cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- sea surface temperature: sst-2010-1 - sst-2010-10\n",
    "- most recent monthly NMME model forecasts for target and average forecast across those models (nmme0mean): nmme0-tmp2m-34w__cancm30, nmme0-tmp2m-34w__cancm40, nmme0-tmp2m-34w__ccsm30, nmme0-tmp2m-34w__ccsm40, nmme0-tmp2m-34w__cfsv20, nmme0-tmp2m-34w__gfdlflora0, nmme0-tmp2m-34w__gfdlflorb0, nmme0-tmp2m-34w__gfdl0, nmme0-tmp2m-34w__nasa0, nmme0-tmp2m-34w__nmme0mean\n",
    "- weeks 3-4 weighted average of most recent monthly NMME model forecasts for target label: nmme-tmp2m-34w__cancm3, nmme-tmp2m-34w__cancm4, nmme-tmp2m-34w__ccsm3, nmme-tmp2m-34w__ccsm4, nmme-tmp2m-34w__cfsv2, nmme-tmp2m-34w__gfdl, nmme-tmp2m-34w__gfdlflora, nmme-tmp2m-34w__gfdlflorb, nmme-tmp2m-34w__nasa, nmme-tmp2m-34w__nmmemean\n",
    "- weeks 5-6 weighted average of most recent monthly NMME model forecasts for target label: nmme-tmp2m-56w__cancm3, nmme-tmp2m-56w__cancm4, nmme-tmp2m-56w__ccsm3, nmme-tmp2m-56w__ccsm4, nmme-tmp2m-56w__cfsv2, nmme-tmp2m-56w__gfdl, nmme-tmp2m-56w__gfdlflora, nmme-tmp2m-56w__gfdlflorb, nmme-tmp2m-56w__nasa, nmme-tmp2m-56w__nmmemean\n",
    "\n",
    "5. Precipitation computed by weather models:\n",
    "- weeks 3-4 weighted average of monthly NMME model forecasts for precipitation: nmme-prate-34w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 5-6 weighted average of monthly NMME model forecasts for precipitation: nmme-prate-56w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 3-4 weighted average of most recent monthly NMME model forecasts for precipitation: nmme0-prate-34w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "- weeks 5-6 weighted average of most recent monthly NMME model forecasts for precipitation: nmme0-prate-56w from weather models cancm30, cancm40, ccsm30, ccsm40, cfsv20, gfdlflora0, gfdlflorb0, gfdl0, nasa0, nmme0mean\n",
    "\n",
    "Features related to El Nino:\n",
    "1. Sea ice concentration: icec-2010-1 - icec-2010-10, where 1-10 - years after the El Nino\n",
    "2. Oscillation coefficients:\n",
    "- Madden-Julian oscillation: mjo1d__phase, mjo1d__amplitude\n",
    "- Multivariate ENSO index (MEI) (associated with El Nino/Southern Oscillation (ENSO)): mei__mei, mei__meirank, mei__nip\n",
    "3. Wind\n",
    "- Longitudinal wind: wind-vwnd-250-2010-1 - wind-vwnd-250-2010-20, wind-vwnd-925-2010-1 - wind-vwnd-925-2010-20\n",
    "- Zonal wind: wind-uwnd-250-2010-1 - wind-uwnd-250-2010-10\n",
    "- Geopotential height wind: wind-hgt-10-2010-1 - wind-hgt-10-2010-10, wind-hgt-100-2010-1 - wind-hgt-100-2010-10, wind-hgt-500-2010-1 - wind-hgt-500-2010-10, wind-hgt-850-2010-1 - wind-hgt-850-2010-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0dvcwryTEDN"
   },
   "source": [
    "### Target investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "os8_R0_cTEDN",
    "outputId": "2b4b5937-cdc9-4369-bda3-fd3f14d02525"
   },
   "outputs": [],
   "source": [
    "# five point summary\n",
    "\n",
    "data['contest-tmp2m-14d__tmp2m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKi9FGF_TEDN",
    "outputId": "243661bc-58b8-4101-af71-d77fbb33762c"
   },
   "outputs": [],
   "source": [
    "attribute_plot(data, 'startdate', 'contest-tmp2m-14d__tmp2m', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxH9JvZXTEDO",
    "outputId": "95a5554b-5530-409a-aa5b-72b9cdc71c2b"
   },
   "outputs": [],
   "source": [
    "distribution(data, 'contest-tmp2m-14d__tmp2m', 'Target distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKDeZjO0TEDO"
   },
   "source": [
    "The target (temperature) has a distribution similar to the normal. However, the average value is not equal to the median value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNKm92z7TEDO"
   },
   "source": [
    "### Locations investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJe9L0M4TEDO",
    "outputId": "a0aeb6e3-a4a3-4a10-d35c-833869faf5ee"
   },
   "outputs": [],
   "source": [
    "# How many locations we have?\n",
    "\n",
    "data.groupby(['lat', 'lon'], as_index=False, sort=False).aggregate('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc-M15n1TEDO"
   },
   "source": [
    "We have 514 locations and 731 measurements for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QxF-wnjTEDP",
    "outputId": "d9f7a335-cc06-4ddf-b2d5-911a98fba969"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['lon'], data['lat'])\n",
    "plt.xlabel(xlabel='latitude')\n",
    "plt.ylabel(ylabel='longitude')\n",
    "plt.title(label='Locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8mcZMC6TEDP"
   },
   "source": [
    "### Climatic regions investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClapZwUITEDP",
    "outputId": "8b5951cf-2820-4d41-9d73-f7984c9c404c"
   },
   "outputs": [],
   "source": [
    "# How many climatic regions we have?\n",
    "\n",
    "data.groupby('climateregions__climateregion', as_index=False).aggregate('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12JeuVlZTEDP"
   },
   "source": [
    "15 climatic regions and different measurements for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SieAaUHRTEDP",
    "outputId": "d00850f8-4222-4573-ea43-c9fdeae5d369"
   },
   "outputs": [],
   "source": [
    "data['climateregions__climateregion'].value_counts().plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UonWUBfeTEDQ"
   },
   "source": [
    "Description:\n",
    "1. B (Dry):\n",
    "- BWh = Hot desert climate\n",
    "- BWk = Cold desert climate\n",
    "- BSh = Hot semi-arid climate\n",
    "- BSk = Cold semi-arid climate\n",
    "2. C (Temperate Climates):\n",
    "- Cfa = Humid subtropical climate\n",
    "- Cfb = Temperate oceanic climate or subtropical highland climate\n",
    "- Csa = Hot-summer Mediterranean climate\n",
    "- Csb = Warm-summer Mediterranean climate\n",
    "3. D (Continental climates):\n",
    "- Dfa = Hot-summer humid continental climate\n",
    "- Dfb = Warm-summer humid continental climate\n",
    "- Dwa = Monsoon-influenced hot-summer humid continental climate\n",
    "- Dwb = Monsoon-influenced warm-summer humid continental climate\n",
    "- Dsb = Mediterranean-influenced warm-summer humid continental climate\n",
    "- Dsc = Mediterranean-influenced subarctic climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kM6v7ysgTEDQ",
    "outputId": "f9360f9c-765a-4b85-e3c5-f9f675a66d5c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(data=data, x='lon', y='lat', hue = 'climateregions__climateregion', palette = 'Spectral')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(xlabel='latitude')\n",
    "plt.ylabel(ylabel='longitude')\n",
    "plt.title(label='Locations of the climatic regions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVRqb9Q8TEDQ",
    "outputId": "e2ab20b4-c2ab-4705-b226-9fd0fe2f6734"
   },
   "outputs": [],
   "source": [
    "# How many locations in each climatic region?\n",
    "\n",
    "data['locations'] = data['lat'].astype(str) + '; ' + data['lon'].astype(str)\n",
    "locations = data[['lat', 'lon', 'climateregions__climateregion', 'locations']].drop_duplicates()\n",
    "locations.groupby('climateregions__climateregion', as_index=False, sort=False).aggregate({'locations' : 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR_il_6VTEDQ",
    "outputId": "ec6855fb-7217-49cf-b49b-abcb0531b76f"
   },
   "outputs": [],
   "source": [
    "# transform climatic regions from categorical to numeric format to work further\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "data['climateregions__climateregion'] = labelencoder.fit_transform(data['climateregions__climateregion'].values)\n",
    "\n",
    "# We can visualize numeric climatic regions to be sure that we have got all 14 regions\n",
    "\n",
    "data['climateregions__climateregion'].value_counts().plot(kind='bar', rot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGn5ooRITEDR",
    "outputId": "58cad253-97b3-4b9c-fe91-c0b8579c0be6"
   },
   "outputs": [],
   "source": [
    "# we can also transform locations from (lat; lon) to just numeric format like the climatic regions to simplify the work\n",
    "\n",
    "data['locations'] = labelencoder.fit_transform(data['locations'].values)\n",
    "data['locations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDVsI8XhTEDR"
   },
   "source": [
    "### Features investigation and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOjDUoy_TEDR"
   },
   "source": [
    "For the modeling step, the environmental features were selected by the team through the provided EDA. That is why only these features takes into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdwXkMgtTEDR",
    "outputId": "16d1f2de-5404-4f80-9831-e841d6ba9edf"
   },
   "outputs": [],
   "source": [
    "environmental_features = data[['startdate', 'lat', 'lon', 'elevation__elevation', 'climateregions__climateregion', 'locations',\\\n",
    "                           'contest-pevpr-sfc-gauss-14d__pevpr', 'contest-rhum-sig995-14d__rhum', \\\n",
    "                           'contest-slp-14d__slp', 'contest-pres-sfc-gauss-14d__pres', 'contest-prwtr-eatm-14d__prwtr',\\\n",
    "                           'contest-precip-14d__precip', 'contest-wind-h10-14d__wind-hgt-10',\\\n",
    "                     'contest-wind-h100-14d__wind-hgt-100', 'contest-wind-h500-14d__wind-hgt-500', \\\n",
    "                     'contest-wind-h850-14d__wind-hgt-850', 'contest-wind-vwnd-250-14d__wind-vwnd-250',\\\n",
    "                     'contest-wind-vwnd-925-14d__wind-vwnd-925','contest-wind-uwnd-250-14d__wind-uwnd-250',\\\n",
    "                     'contest-wind-uwnd-925-14d__wind-uwnd-925', 'contest-tmp2m-14d__tmp2m']]\n",
    "\n",
    "# rename some features for the clear description\n",
    "\n",
    "environmental_features = environmental_features.rename(columns={'elevation__elevation': 'elevation', \\\n",
    "                                                                'climateregions__climateregion': 'climateregion',\\\n",
    "                                                               'contest-pevpr-sfc-gauss-14d__pevpr': 'evaporation',\\\n",
    "                                                               'contest-rhum-sig995-14d__rhum': 'humidity',\\\n",
    "                                                               'contest-slp-14d__slp': 'sea_level_pressure',\\\n",
    "                                                               'contest-pres-sfc-gauss-14d__pres': 'pressure',\\\n",
    "                                                               'contest-prwtr-eatm-14d__prwtr': 'precipitable_water',\n",
    "                                                               'contest-precip-14d__precip': 'precipitation',\\\n",
    "                                                               'contest-wind-h10-14d__wind-hgt-10': 'wind_height_10',\\\n",
    "                                                               'contest-wind-h100-14d__wind-hgt-100': 'wind_height_100',\\\n",
    "                                                               'contest-wind-h500-14d__wind-hgt-500': 'wind_height_500',\\\n",
    "                                                               'contest-wind-h850-14d__wind-hgt-850': 'wind_height_850',\\\n",
    "                                                               'contest-wind-vwnd-250-14d__wind-vwnd-250': \\\n",
    "                                                                'long_wind_250', 'contest-wind-vwnd-925-14d__wind-vwnd-925':\\\n",
    "                                                               'long_wind_925', 'contest-wind-uwnd-250-14d__wind-uwnd-250':\\\n",
    "                                                               'zonal_wind_250', 'contest-wind-uwnd-925-14d__wind-uwnd-925':\\\n",
    "                                                               'zonal_wind_925', 'contest-tmp2m-14d__tmp2m': 'temperature'})\n",
    "\n",
    "# five point summary\n",
    "\n",
    "environmental_features.drop(columns={'startdate', 'lat', 'lon', 'climateregion', 'locations'}).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0PtLGGITEDR",
    "outputId": "04c48e3e-de57-4b56-ff96-692215522446"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "corr_matrix = environmental_features.drop(columns={'startdate', 'lat', 'lon', 'climateregion', 'locations'}).corr()\n",
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i46ySTuATEDS"
   },
   "source": [
    "The heatmap shows that\n",
    "1. we have high correlation between some features (|correlation|> 0.75):\n",
    "- elevation and pressure = -0.92\n",
    "- evaporation and humidity = -0.76\n",
    "- evaporation and wind height 10 = 0.75\n",
    "- wind height 10 and wind height 100 = 0.83\n",
    "- evaporation and wind height 100 = 0.82\n",
    "- evaporation and wind height 500 = 0.79\n",
    "- wind height 100 and wind height 500 = 0.96\n",
    "2. we have high correlation between temperature and \n",
    "- evaporation = 0.81\n",
    "- precipitable water = 0.77\n",
    "- wind height 10 = 0.76\n",
    "- wind height 100 = 0.9\n",
    "- wind height 500 = 0.88\n",
    "3. we have low correlation (|correlation|< 0.5) between temperature and\n",
    "- precipitation = 0.079\n",
    "- elevation = -0.21\n",
    "- pressure = 0.24\n",
    "- longitudinal wind 250 = 0.43\n",
    "- longitudinal wind 925 = 0.27\n",
    "- zonal wind 250 = -0.33\n",
    "- zonal wind 925 = -0.37\n",
    "\n",
    "The variables must be independent between each other. Therefore the high correlated features should be excluded at the modeling stage. The low correlated features should be also excluded as the less informative.\n",
    "We can remove wind height 10 and wind height 500. Although evaporation and temperature are high correlated we can also try to remove evaporation because of its high correlation with humidity and wind height 100, and observe what we will get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poaLgT67TEDS"
   },
   "outputs": [],
   "source": [
    "environmental_features_selected = environmental_features.drop(columns={'evaporation', 'wind_height_10', 'wind_height_500',\\\n",
    "                                                                       'elevation', 'precipitation', 'pressure',\\\n",
    "                                                                       'long_wind_250', 'long_wind_925', 'zonal_wind_250',\n",
    "                                                                       'zonal_wind_925'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMQTp3bRTEDS",
    "outputId": "af1da29f-da7e-41b5-9318-0034cdf516ff"
   },
   "outputs": [],
   "source": [
    "corr_matrix_selected = environmental_features_selected.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".corr()\n",
    "sns.heatmap(corr_matrix_selected, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCJ7q0TITEDS"
   },
   "source": [
    "We have got 5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZZtblRDTEDS",
    "outputId": "c32cb296-dc6b-4910-971f-2e12677f059b"
   },
   "outputs": [],
   "source": [
    "# features simple visualization\n",
    "\n",
    "environmental_features_selected.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".plot(figsize = (22, 16), subplots=True, layout=(len(environmental_features_selected.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BV4DpZ0TEDT"
   },
   "source": [
    "We have 514 locations and 14 climatic regions. The measurements are spread on the graphs through the whole time period.\n",
    "\n",
    "To try modeling step and interpret the results correctly, we can start simply from one location. Location # 1 for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phceS0giTEDT"
   },
   "source": [
    "### Single location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBonW699TEDT",
    "outputId": "278886d7-d9d4-4f70-df9e-c742c719dd4d"
   },
   "outputs": [],
   "source": [
    "location_number = 10 # choose the number of location\n",
    "single_location = environmental_features_selected[environmental_features_selected['locations'] == location_number]\n",
    "single_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmOmBOnHTEDT",
    "outputId": "52864646-3139-4774-f2b5-f3e66e8e99bc"
   },
   "outputs": [],
   "source": [
    "# features simple visualization\n",
    "\n",
    "single_location.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".plot(figsize = (22, 16), subplots=True, layout=(len(single_location.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wdlcm25TEDT"
   },
   "source": [
    "Now we can see variables dynamic for location # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XEu3sw7TEDU"
   },
   "source": [
    "and their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9nh2WxVMTEDU",
    "outputId": "3042ffcb-a34e-4759-b3d1-f4b8dceb16b2"
   },
   "outputs": [],
   "source": [
    "single_location.drop(columns={'lat', 'lon', 'startdate', 'climateregion', 'locations'})\\\n",
    ".hist(figsize = (8, 30), layout=(len(single_location.columns),1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7BmjQ6MTEDU"
   },
   "source": [
    "### Features preparations to the modeling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1KkadHvTEDU",
    "outputId": "605a2f1d-eb0f-494e-9466-a1c25ed7ab7e"
   },
   "outputs": [],
   "source": [
    "# we take only date and necessary features for the prediction\n",
    "\n",
    "single_location = single_location.drop(columns={'lat', 'lon', 'climateregion', 'locations'}).set_index('startdate')\n",
    "single_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zkq-yCATTEDU",
    "outputId": "fdb05c94-c5b7-4956-80b6-64e4e669ed68"
   },
   "outputs": [],
   "source": [
    "single_location.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eac4NF5tTEDU"
   },
   "outputs": [],
   "source": [
    "# normalizing the features\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset = scaler.fit_transform(single_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp_Mzd1CTEDV"
   },
   "source": [
    "This tutorial was used for the futher work:\n",
    "https://www.kaggle.com/code/mineshjethva/time-series-forecasting-with-lstm-for-uni-multivar/notebook\n",
    "\n",
    "We are going to use a multivariate approach since we have 5 features and the temperature itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htSfKKGuTEDV"
   },
   "source": [
    "To lean by steps, firstly we will try to predict the values of the temperature for the next 14 days for one location by building LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtF0kNb6TEDV"
   },
   "source": [
    "We have 731 observations and one measurement per day. \n",
    "In order to make this prediction, we choose to use 7 days of observations (is chosen via experiments for the model as an optimal one). \n",
    "Thus, we would create a window containing the last 7 observations to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxxLkAZcTEDV"
   },
   "outputs": [],
   "source": [
    "# The function below returns the above described windows of time for the model to train on\n",
    "\n",
    "# history_size is the size of the past window of information\n",
    "# target_size is how far in the future does the model need to learn to predict, is the label that needs to be predicted\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size, step):\n",
    "# \"multivariate\" means that we use several features (not one)\n",
    "    data = [] # for x_train/validation\n",
    "    labels = [] # for y_train/validation\n",
    "    start_index = start_index + history_size\n",
    "    \n",
    "    if end_index is None: # for the validation part\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index): # sequences creation \n",
    "        indices = range(i-history_size, i, step)\n",
    "        data.append(dataset[indices])\n",
    "        labels.append(target[i:i+target_size])\n",
    "        \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfEQk3W3TEDW"
   },
   "source": [
    "We do not use our test dataset and split the training dataset into training and validation parts to adjust the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j489TJWATEDW"
   },
   "outputs": [],
   "source": [
    "# setting the inputs for the function\n",
    "\n",
    "training_size = int(0.8*dataset.shape[0]) # define the size of training part\n",
    "start_index = 0\n",
    "end_index = training_size\n",
    "history_size = 7 # is the size of the past window of information\n",
    "target_size = 14 # days, is how far in the future does the model need to learn to predict, \n",
    "#is the label that needs to be predicted\n",
    "step = 1 # we have one measurement per day that is one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQHrH4ZGTEDW"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into training and validation parts and transforming it with the described window\n",
    "\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, -1], start_index, end_index, history_size, target_size,\\\n",
    "                                                 step)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, -1], start_index, None, history_size, target_size, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S64Mu_d6TEDX"
   },
   "source": [
    "Now we are ready to build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0maRyrATEDX"
   },
   "source": [
    "### Building LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ijft0-j6TEDX"
   },
   "outputs": [],
   "source": [
    "# functions for plotting the results\n",
    "\n",
    "# creating time steps for plotting\n",
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))\n",
    "\n",
    "# plotting predictions\n",
    "def multi_step_plot(history, true_future, prediction, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, -1]), label='History')\n",
    "    plt.plot(np.arange(num_out)/step, np.array(true_future), 'bo', label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/step, np.array(prediction), 'ro', label='Predicted Future')\n",
    "    plt.ylim(top=1, bottom=0)\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.title(title)\n",
    "    plt.savefig('prediction_plot.png', facecolor='w', edgecolor='w')\n",
    "    \n",
    "# plotting loss results    \n",
    "def plot_train_history(history, title):\n",
    "    # the loss is mse in the model configuration, and we calculate rmse by tf.sqrt for the task goal\n",
    "    loss = tf.sqrt(history.history['loss']) \n",
    "    val_loss = tf.sqrt(history.history['val_loss'])\n",
    "\n",
    "    epochs = range(len(loss))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.ylim(top=0.2)\n",
    "    plt.title(title)\n",
    "    plt.savefig('loss_plot.png', facecolor='w', edgecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj4J0-weTEDY"
   },
   "outputs": [],
   "source": [
    "# We use tensorflow and keras to work with LSTM\n",
    "\n",
    "# perform shuffling, batching, and caching the dataset\n",
    "\n",
    "BATCH_SIZE = 16 # is chosen via experiments for the model as an optimal one\n",
    "# about batch size https://ai.stackexchange.com/questions/8560/how-do-i-choose-the-optimal-batch-size\n",
    "BUFFER_SIZE = 10000 # 10000 in tutorial\n",
    "# about buffer size \n",
    "#https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "\n",
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9CsN5JQTEDY"
   },
   "outputs": [],
   "source": [
    "# constructing the model\n",
    "\n",
    "multi_step_model = tf.keras.models.Sequential() # layers creating \n",
    "# the first layer\n",
    "# activation functions are 'tanh' and recurrent_activation='sigmoid'\n",
    "multi_step_model.add(tf.keras.layers.LSTM(64, # 32 neurons in tutorial\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:])) \n",
    "# the second layer\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32, activation='relu', return_sequences=True)) # 32 neurons, activation 'relu' in tutorial\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='softmax')) # 32 neurons, activation 'relu' in tutorial\n",
    "# the output layer\n",
    "multi_step_model.add(tf.keras.layers.Dense(14)) # since 14 predictions are made \n",
    "# the dense layer outputs 14 predictions\n",
    "\n",
    "# configures the model for training\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mse', metrics=['accuracy']) # learning_rate=0.001 as default\n",
    "# clipvalue: If set, the gradient of each weight is clipped to be no higher than this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLEH5e8eTEDY",
    "outputId": "05228a0b-b073-48d3-c0a4-35c1423ae5dd"
   },
   "outputs": [],
   "source": [
    "multi_step_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9zdP5jrTEDZ",
    "outputId": "0690ada8-1aea-45ce-f123-65dfb5dd74bd"
   },
   "outputs": [],
   "source": [
    "# how the model predicts before it trains\n",
    "\n",
    "for x, y in val_data_multi.take(1): # .take () creates a dataset with at most count elements from this dataset\n",
    "    # representing the number of elements of this dataset that should be taken to form the new dataset\n",
    "    print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qGQaUbgTEDZ",
    "outputId": "bf657ab8-c626-47ef-cf6b-00ff32d8c638"
   },
   "outputs": [],
   "source": [
    "multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0], 'How the model predicts before it trains')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kzY17KvTEDZ",
    "outputId": "760eced2-64c2-47f9-e3f9-45160f3e2b91"
   },
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "EVALUATION_INTERVAL = training_size \n",
    "# steps per epoch is calculated as train_length // batch_size, 200 in tutorial (is said that complete training data is normal)\n",
    "EPOCHS = 20 # 20 in tutorial\n",
    "\n",
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50) \n",
    "# validation_steps = total_validation_samples // validation_batch_size\n",
    "# validation_batch_size If unspecified, will default to batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvaIUeVkTEDZ",
    "outputId": "78a4ea80-90d3-4dc6-82c1-b841a64215ee"
   },
   "outputs": [],
   "source": [
    "# the history and the future data are sampled every day\n",
    "for x, y in train_data_multi.take(1):\n",
    "    multi_step_plot(x[0], y[0], np.array([0]), 'True future values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqKR-QKSTEDZ",
    "outputId": "4bc1ccf8-0b0d-4b17-fe67-569c53b7c926"
   },
   "outputs": [],
   "source": [
    "# loss function results\n",
    "plot_train_history(multi_step_history, 'Multi-Step training and validation loss, RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2sa-ecA9TEDa",
    "outputId": "40878d9a-393b-4a5a-e0f8-20fdea049729"
   },
   "outputs": [],
   "source": [
    "# the history, the true and predicted future data are sampled every day\n",
    "for x, y in val_data_multi.take(1): \n",
    "    multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0], 'How the model predicts after training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TBMdNJFTEDa",
    "outputId": "87e645c0-fd65-4f83-af07-eddeecda7ab3"
   },
   "outputs": [],
   "source": [
    "# plotting error distribution for 14 predictions\n",
    "error = pd.DataFrame({'error':y[0] - multi_step_model.predict(x)[0]})\n",
    "error = error.reset_index()\n",
    "error = error.drop(columns=['index'])\n",
    "error.plot.hist()\n",
    "plt.ylim(top=7)\n",
    "plt.title('Error distribution')\n",
    "plt.savefig('error_distribution.png', facecolor='w', edgecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRnKaK2bTEDa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
